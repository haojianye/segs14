\section{Introduction}

Power grid is one of the most critical infrastructures in existence today, whose disruption could cause severe economic, social, and environmental damages \cite{brown2006defending,salmeron2004analysis}, making it an attractive target for attackers. Protecting a power grid poses a number of challenges due to its wide geographical spread and complex interdependences among its components. To make the matter worse, modern grid systems are connected to the Internet, exposing itself to a wide range of cyber-attacks.

One active area of research in smart grid security focuses on applying game-theoretic frameworks to analyze the interactions between system defenders and attackers \cite{saad2012game}. One commonly adopted game-theoretic model is called a Markov game \cite{minmaxQ}, where the players' joint actions lead to probabilistic transitions between states of the system. In the previous applications of a Markov game to a smart grid attack, a \textit{Nash equilibrium} (NE) solution is computed as the optimal defending strategy \cite{law2012security,ma2013markov}. 

The proposal on adopting a NE strategy is based on one crucial assumption: the attacker would also employ the corresponding NE strategy to attack the system. In practice, for a system as complex as a smart grid, the attacker may have neither a perfect knowledge of the system nor the computational capacity required to compute a NE strategy. More realistically, the attacker uses its experience and partial knowledge of the system to formulate what he/she believes to be the best strategy for maximizing the damage. Thus, it may be possible for the defender to employ a non-NE strategy that is just as effective, and potentially cheaper. The technical challenge is determining the attacker's behavior (initially unknown) and reformulate the defender's strategy dynamically.

%This kind of analysis is usually based on the assumption that the attackers are strategic and individually rational in maximizing the possible cost incurred on the system. One commonly adopted game-theoretic model is the Stackelberg game, which models the strategic interaction among defender and attacker as a two-player single-shot sequential game. This kind of modeling is based on the assumption that the attacker has the capability to observe the protection strategy of the defender through extensive surveillance, which usually might not be feasible in practice.

We propose a novel approach called an \underline{a}daptive \underline{M}arkov \underline{s}trategy (AMS) for defending a system against attackers with \emph{unknown, dynamic} behaviors. Our AMS algorithm leverages an adaptive online learning technique to observe the attacker's behavior and reformulate an optimal defense strategy dynamically. It is guaranteed to converge to a best-response strategy against any stationary attacker, and also converges to a Nash equilibrium if the attacker is sufficiently intelligent to employ the AMS to launch the attack.

To demonstrate the effectiveness of our approach, we applied it to a class of smart grid attacks that involve injecting false voltage information into a grid substation, disrupting its voltage stability and causing load shedding. We experimentally evaluated the performance of our approach by applying it to a sample distribution system from the previous work \cite{law2012security}. Our preliminary results show that the amount of load shedding cost can be significantly reduced by employing an AMS over a NE strategy. Although we focus on one particular type of security attacks in this paper, our learning framework is general, and applicable to other classes of attacks that can be modeled as a Markov game.

The rest of the paper is organized as follows. We give an overview of related work in Section \ref{relatedwork}. In Section \ref{problemdefinition}, we describe the false data injection attack and how this problem can be modeled as a Markov game. We present the AMS strategy and its properties in Section \ref{amsstrategy}, and describe an evaluation of our approach in Section \ref{simulation}. We conclude with a discussion of future work in Section \ref{conclusion}.
